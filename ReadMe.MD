#Computer Graphis Term Project

Development Environment : Android
Implementation Complete!!


##Implementation
-모든 개발은 Unity로 이루어졌다.

-본 프로젝트의 주된 목표는 물체의 반사와 굴절을 동시에 구현하여 GearVR에서 물체들의 사이를 이동하며 다양한 각도의 물체를 시각적으로 확인하는 것이다, 컴퓨터그래픽스 강의에서 배웠듯이, 반사와 굴절을 동시에 구현하는 기법 중 가장 유명한 것은 Ray Tracing이지만, 알고리즘이 간단한 대신 소모되는 자원양이 어마어마하다. 특히 GearVR에서의 Ray Tracing 사용은 어려울 것이라 판단하여 다른 기법을 고려할 필요가 있다.

-결론적으로 구현해야 할 것은 물체의 반사와 굴절뿐이므로, 아예 렌더링을 두 번 하는 방법을 선택했다. 먼저 굴절을 계산하여 렌더링하고 그 뒤 반사를 계산하여 렌더링하여 둘을 조합시키는 것이다.

-굴절 자체는 크게 어려운 것이 아니다. 카메라에서 물체를 통과한 화면의 좌표를 일정한 값으로 어긋나게 하여 간단하게 구현했다. 반사는 굴절에 비해 좀 어렵게 느껴지는데, 여기서 떠올린 방법이 Cube Map을 이용한 Fresnel 렌더링이다. 현재 사물의 위치에서 사방을 찍어 Cube Map을 저장하여 재질에 따른 계산을 거친 후 Fresnel 효과를 적용시켜 물체의 현실감을 더하고 자원도 아낄 수 있었다.

-그러나 이 또한 GearVR에서 구현되어야하기 때문에 Cube Map을 리얼타임이 아닌 프로젝트 빌드 시 찍도록 설정하였다. 또한 서로 상호작용해야하지만 Cube mapping의 한계상 Cube Map을 찍을 때 주변의 물체들은 불투명한 Material로 설정하였다.

-이렇게 구현된 굴절과 반사를 텍스처에 입히고 세부 조정을 하면 목표로 하던 구현은 전부 완료되었다. 흰 기물은 투명하며, 검은 기물은 검은 색이 섞인 반투명한 상태로 나타난다.

-기물은 체스판에서 움직이지 않지만 카메라가 돌아다니며 물체의 반사와 굴절을 확인할 수 있다. 이때 카메라의 움직임은 GearVR에서 이루어지며 이를 구현하기 위해 오큘러스에서 제공하는 OVRPlayerContoller 스크립트를 이용하였다. 헤드트래킹으로 카메라의 시점이 바뀌며, GearVR이 입력한 값을 설정하여 GearVR의 터치패드를 조작하면 카메라가 움직일 수 있게 구현하였다.

-컴퓨터에서 개발한 것과 달리 스마트폰에서는 구현된 프로젝트가 부드럽게 작동되지 않았다. 컴퓨터의 리소스와 스마트폰의 리소스 차가 심해서 나타나는 현상으로, 본 프로젝트의 개발환경이 스마트폰인만큼 스마트폰에서의 부드러운 움직임이 중요한 부분이다. 프로젝트를 최적화하기 위해 몇몇 빌드 설정을 바꿨으며 또 폴리곤 수를 줄이는 방법을 사용하였다.

-폴리곤 수를 줄이는 데에 사용한 것은 Unity의 Asset Store에 등록되어있는 Simplygon이라는 이름의 Plug-in으로, 서버에 지정한 Mesh를 보내 자체 알고리즘으로 기본적인 모습은 유지한 채 폴리곤의 수를 줄이는 프로그램이다.

##Strategy
-프로젝트의 주제는 빛에 관련된 그래픽스이다. 물체의 빛의 반사, 빛의 굴절 등을 구현할 것이고, 반투명한 물체를 통해 움직이는 사물을 보이고자 한다. 이 반투명한 물체는 사물을 어느 정도 반사하는 재질을 갖게 할 것이다. 또한 전구와 같은 빛을 발하는 광원을 만들어 각 사물이 그 빛에 영향을 받게 하여 빛에 따른 사물의 변화를 보일 것이다. 팀원 세 명 다 안드로이드 환경에서의 개발에 동의하여 안드로이드 환경에서 제작한다.

-반투명한 물체는 여러 후보가 있다. 크기가 다양한 색이 있는 액체를 담은 유리병, 크기가 다양한 색유리, 필름 등이 그 예이다. 빛을 투과하여 왜곡시키고 사물이 어느 정도 반사되는 재질을 가질 것이다. 이 물체들을 몇 개 배치하고, 카메라의 위치에 따라 다르게 보인다.

-움직이는 사물은 사람, 자동차, 동물 등이지만 보이고자 하는 것은 투과된 사물의 변화이므로 이 사물이 어떠한 사물인지는 중요하지 않다. 수는 반투명한 물체보다 적고, 몇 가지 경로를 지정하여 그 경로에 따라 자동으로 움직이게 한다. 역시 카메라의 위치에 따라 다르게 보인다.

-광원은 천장에 해당하는 위치에 배치한다. 여러 군데에서 빛을 발산시키지만 빛을 적게 받는 공간 역시 존재한다.

-카메라의 위치는 일정하지 않다. 움직이는 사물 – 반투명한 물체 – 카메라 혹은 반투명한 물체 – 사물 – 카메라 순으로 배열되거나 혹은 두 가지가 혼합된 화면을 보일 수 있다. 경우에 따라 사물에 어느 정도 반사된 사물들이 보이지 않는 시점이 존재한다.

-사용자의 입력을 받아 위치와 시선이 자유롭게 변하며, 그에 따라 사물이 빛을 반사하는 모양이 다르게 보일 수 있다. 카메라는 사물이나 물체를 통과할 수 없으며, 움직일 수 있는 일정한 범위가 존재한다. 특히 사용자의 입력에 딜레이가 거의 없이 상호적인 움직임을 보이는 것이 중요하다.

-배치한 체스 말을 활용하는 방법을 모색하고 있다. 체스 말을 자동으로 움직이게 하거나, 사용자의 입력을 받아 체스 말의 위치를 지정하는 방식을 고려하고 있다. 다양한 각도를 보이기 위해서는 체스 말을 움직이게 하는 것이 좋지만 후술할 카메라가 이미 체스 말 사이를 자유롭게 움직이기 때문에 구현하지 않을 가능성이 크다. 따라서 프로젝트를 실행할 때 사용자가 각 기물들의 위치를 지정하는 방법을 고려하고 있다.

-카메라는 사용자의 입력을 받아서 체스판 위를 자유롭게 움직이며 다양한 각도에서 다양한 화면을 보여준다. 굴절을 다양한 각도에서 보여주기 때문에 비교하며 움직일 수 있다. 키보드를 통해 카메라의 위치를 조절할 수 있고 마우스를 통해서는 카메라의 시야를 다룰 수 있다. 만약 프로젝트에 GearVR을 적용시킨다면 키보드나 입력패드로 카메라를 움직이고 시야를 사용자의 머리 움직임으로 다룰 예정이다.

##Member
-2014190706 김용훈

-2014190714 김한마루

-2014190716 박소윤